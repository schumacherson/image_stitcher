{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#escolhe o método de extração de keypoints\n",
    "feature_extractor = 'sift'\n",
    "\n",
    "#são lidas as imagens\n",
    "images = [cv2.imread(file) for \n",
    "          file in sorted(glob.glob(\"caminho_das_imagens/*.jpg\"))]\n",
    "\n",
    "#diminui-se a resolução das imagens para que o tempo de execução seja menor\n",
    "images = [cv2.resize(images[i], (int(images[i].shape[1]*0.5), int(images[i].shape[0]*0.5))) \n",
    "          for i in range(len(images))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cria o objeto que opera o algoritmo de detecção de keypoints\n",
    "def detectAndDescribe (image, method=None):\n",
    "        \n",
    "    if method == 'sift':\n",
    "        descriptor = cv2.SIFT_create()\n",
    "    elif method == 'orb':\n",
    "        descriptor = cv2.ORB_create()\n",
    "    elif method == 'brisk':\n",
    "        descriptor = cv2.BRISK_create()\n",
    "        \n",
    "    (kps, features) = descriptor.detectAndCompute(image, None)\n",
    "    \n",
    "    return (kps, features)\n",
    "\n",
    "#cria o objeto que corresponde os keypoints de duas imagens\n",
    "def createMatcher(method, crossCheck):\n",
    "    if method == 'sift':\n",
    "        bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=crossCheck)\n",
    "    else:\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=crossCheck)\n",
    "    \n",
    "    return bf\n",
    "\n",
    "#realiza a correspondência de pontos\n",
    "def matchKeypointsKNN(featuresA, featuresB, ratio, method):\n",
    "    bf = createMatcher(method, crossCheck=False)\n",
    "    \n",
    "    rawMatches = bf.knnMatch(featuresA, featuresB, 2)\n",
    "    matches = []\n",
    "    \n",
    "    for m,n in rawMatches:\n",
    "        if m.distance < n.distance * ratio:\n",
    "            matches.append(m)\n",
    "    return matches  \n",
    "\n",
    "#opera o grafo e encontra o caminho que será percorrido\n",
    "def breadth(grafo, inicio):\n",
    "    visited = [False]*len(grafo)\n",
    "    \n",
    "    final = []\n",
    "    \n",
    "    queue = []\n",
    "    \n",
    "    queue.append(inicio)\n",
    "    visited[inicio] = True\n",
    "    \n",
    "    while queue:\n",
    "        inicio = queue.pop(0)\n",
    "        print(inicio, end=\" \")\n",
    "        final.append(inicio)\n",
    "        \n",
    "        for i in grafo[inicio]:\n",
    "            if visited[i] == False:\n",
    "                queue.append(i)\n",
    "                visited[i] = True\n",
    "                \n",
    "    return final\n",
    "    \n",
    "#encontra a homografia que sobrepõe a imagem B na imagem A\n",
    "def getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh):\n",
    "    kpsA = np.float32([kp.pt for kp in kpsA])\n",
    "    kpsB = np.float32([kp.pt for kp in kpsB])\n",
    "    \n",
    "    if len(matches) > 4:\n",
    "\n",
    "        ptsA = np.float32([kpsA[m.queryIdx] for m in matches])\n",
    "        ptsB = np.float32([kpsB[m.trainIdx] for m in matches])\n",
    "        \n",
    "        (H, status) = cv2.findHomography(ptsB, ptsA, cv2.RANSAC, reprojThresh)\n",
    "\n",
    "        return H\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#encontra a máscara de uma imagem\n",
    "def get_mask(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    mask = cv2.threshold(gray, 0, 1, cv2.THRESH_BINARY)[1]\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask = 1 - mask\n",
    "    \n",
    "    return mask\n",
    "\n",
    "#realiza o blending de duas imagens\n",
    "def merge(imgA, imgB, mask):\n",
    "    maskA = 1 - mask\n",
    "    \n",
    "    fim = imgA * mask + imgB * maskA\n",
    "        \n",
    "    return fim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0 1 3 4 5 "
     ]
    }
   ],
   "source": [
    "threshold = 150 #quantidade mínima de matches para que dois vértices se liguem via aresta no grafo\n",
    "\n",
    "grafo = {}\n",
    "\n",
    "infoImg = {}\n",
    "\n",
    "matching = {}\n",
    "\n",
    "nbr_imgs = len(images)\n",
    "\n",
    "for i in range(nbr_imgs):\n",
    "    grafo[i] = [] #inicializa o grafo, criando sua lista de adjacências vazia\n",
    "\n",
    "for i in range(0, nbr_imgs):\n",
    "    for j in range(0, nbr_imgs):\n",
    "        imgA = images[i]\n",
    "        imgB = images[j]\n",
    "        \n",
    "        kpsA, featuresA = detectAndDescribe(imgA, method=feature_extractor)\n",
    "        kpsB, featuresB = detectAndDescribe(imgB, method=feature_extractor)\n",
    "        \n",
    "        infoImg[i] = (kpsA, featuresA)\n",
    "        infoImg[j] = (kpsB, featuresB)\n",
    "\n",
    "        matches = matchKeypointsKNN(featuresA, featuresB, ratio=0.3, method=feature_extractor)\n",
    "            \n",
    "        if len(matches) > threshold and i!=j: #cria a aresta entre vértices caso cumpram a condição\n",
    "            grafo[i].append(j)\n",
    "            matching[(i, j)] = matches\n",
    "        \n",
    "escolhaArray = [len(grafo[i]) for i in range(len(images))]\n",
    "\n",
    "escolha = escolhaArray.index(max(escolhaArray))\n",
    "\n",
    "percurso = breadth(grafo, escolha) #ordem de colagem das imagens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "usados = []\n",
    "homografias = {} #guarda as homografias entre imagens\n",
    "caminhos = {} #caminho que cada vértice tem que fazer para chegar na imagem central\n",
    "\n",
    "for i in range(len(percurso)):\n",
    "    caminhos[percurso[i]] = []\n",
    "\n",
    "for i in range(len(percurso)):\n",
    "    for j in range(len(grafo[percurso[i]])):\n",
    "        if  grafo[percurso[i]][j] not in usados:\n",
    "            \n",
    "            infoA = infoImg[percurso[i]]\n",
    "            infoB = infoImg[grafo[percurso[i]][j]]\n",
    "\n",
    "            (kpsA, featuresA) = infoA\n",
    "            (kpsB, featuresB) = infoB\n",
    "\n",
    "            matches = matching[(percurso[i], grafo[percurso[i]][j])]\n",
    "\n",
    "            H = getHomography(kpsA, kpsB, featuresA, featuresB, matches, reprojThresh = 4)\n",
    "            \n",
    "            homografias[(percurso[i], grafo[percurso[i]][j])] = H #salva as homografias\n",
    "            \n",
    "            caminhos[grafo[percurso[i]][j]].append(percurso[i])\n",
    "            \n",
    "            for k in range(len(caminhos[percurso[i]])):\n",
    "                caminhos[grafo[percurso[i]][j]].append(caminhos[percurso[i]][k])\n",
    "            \n",
    "            usados.append(grafo[percurso[i]][j])\n",
    "    \n",
    "    usados.append(percurso[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3850 2821\n"
     ]
    }
   ],
   "source": [
    "#encontra a resolução final da imagem\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "finais = {}\n",
    "\n",
    "imagesCopy = images.copy()\n",
    "\n",
    "for i in range(len(percurso)):\n",
    "    w = imagesCopy[percurso[i]].shape[1]\n",
    "    h = imagesCopy[percurso[i]].shape[0]\n",
    "    \n",
    "    ordemAc = caminhos[percurso[i]].copy()\n",
    "    ordemAc.reverse()\n",
    "    ordemAc.append(percurso[i])\n",
    "    \n",
    "    final = np.identity(3)\n",
    "    \n",
    "    if len(ordemAc) > 1:\n",
    "        for j in range(len(ordemAc) - 1):\n",
    "            sup = homografias[(ordemAc[j], ordemAc[j+1])]\n",
    "            final = np.dot(final, sup)\n",
    "    \n",
    "    finais[percurso[i]] = final\n",
    "    \n",
    "    p1 = [0, 0, 1]\n",
    "    p2 = [w, 0, 1]\n",
    "    p3 = [0, h, 1]\n",
    "    p4 = [w, h, 1]\n",
    "    p = [p1, p2, p3, p4]\n",
    "    \n",
    "    for pi in p:\n",
    "        res = np.dot(final, pi)\n",
    "        xs.append(res[0])\n",
    "        ys.append(res[1])\n",
    "    \n",
    "width = int(max(xs) - min(xs)) + 1\n",
    "heigth = int(max(ys) - min(ys)) + 1\n",
    "\n",
    "print(width, heigth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate = np.array([\n",
    "    [1, 0, -min(xs)],\n",
    "    [0, 1, -min(ys)],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "#esta matriz será aplicada em cada uma das imagens, para levá-las ao centro do canvas\n",
    "\n",
    "to_blend = []\n",
    "\n",
    "#transforma cada imagem, deixando elas no seu lugar final do mosaico\n",
    "\n",
    "for i in range(len(percurso)):\n",
    "    img = imagesCopy[percurso[i]]\n",
    "    \n",
    "    final = translate.copy()\n",
    "            \n",
    "    final = np.dot(final, finais[percurso[i]])\n",
    "    \n",
    "    transformed = cv2.warpPerspective(img, final, (width, heigth))\n",
    "    cv2.imwrite(\"transformado_{}.png\".format(i), transformed)\n",
    "    \n",
    "    to_blend.append(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blending = to_blend.copy()\n",
    "\n",
    "#realiza o blending com todas as imagens\n",
    "\n",
    "for i in range(1, len(to_blend)):\n",
    "    imgA = blending[i-1]\n",
    "    imgB = blending[i]\n",
    "        \n",
    "    mask = get_mask(imgB)\n",
    "    \n",
    "    resultado = merge(imgA, imgB, mask)\n",
    "        \n",
    "    blending[i] = resultado\n",
    "    \n",
    "cv2.imwrite(\"resultado_final1.png\", resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
